{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzNng6vCL9eP"
   },
   "source": [
    "#EITQ TP4: Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vJLt3JRL9eR"
   },
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84TUvrPZgmoo"
   },
   "source": [
    "This tutorial is built around the examples from the `treelib` and `tatsu` documentations, as well as a [regexp](https://github.com/tesla809/intro-to-python-jupyter-notebooks/blob/master/47-Regular%20Expressions.ipynb) tutorial.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVrTo-LhL9eS"
   },
   "source": [
    "##Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1PvreR9L9eW"
   },
   "source": [
    "The tutorial covers:\n",
    "\n",
    "*   Trees\n",
    "*   Regular expressions\n",
    "*   Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxvEkGXPM3Xh"
   },
   "source": [
    "## Python Versions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZWlbMV7gug2"
   },
   "source": [
    "We'll be using Python 3. You can check your Python version at the command line by running `python --version`. In Colab, we can enforce the Python version by clicking `Runtime -> Change Runtime Type` and selecting `python3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1L4Am0QATgOc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.8\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNWUGRMJaMGQ"
   },
   "source": [
    "## Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpANhS5S82XM"
   },
   "source": [
    "There are many ways to organize your data in the memory of a computer. Each different way is referred to as a *data structure*.\n",
    "\n",
    "For instance, we experimented with lists and dictionnaries. Those data structures are native in python. \n",
    "\n",
    "We also experimented with object-oriented programming (OOP). We saw that lists could be reimplemented through OOP. OOP lets you implement whatever data structure you may need, way beyond those that are native in python.\n",
    "\n",
    "One of the most useful data structure in Computer Science is that of [trees](https://en.wikipedia.org/wiki/Tree_%28data_structure%29). \n",
    "\n",
    "Trees are not native in python, but of course they have been implemented many times in many libraries. Let us experiment with one of them, before you make your own trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMeIBT32AK1D"
   },
   "source": [
    "First we install the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwxsugJP8wZm",
    "outputId": "8cfe9b83-2ba6-4dca-9208-8a1199c3450a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: treelib in /home/joseph/.local/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: future in /usr/lib/python3.10/site-packages (from treelib) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install treelib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iC2Ti2-JAUtj"
   },
   "source": [
    "Next we import trees and their nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b_psaP6D8spc"
   },
   "outputs": [],
   "source": [
    "from treelib import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hGPCT6PAlHr"
   },
   "source": [
    "Now we build a tree and visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaErBUmpAqwU",
    "outputId": "3079da0e-ee71-4e34-800b-f3ea0bc1396e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry\n",
      "├── Bill\n",
      "└── Jane\n",
      "    ├── Diane\n",
      "    │   └── Mary\n",
      "    └── Mark\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = Tree()\n",
    "tree.create_node(\"Harry\", \"harry\")  # root node\n",
    "tree.create_node(\"Jane\", \"jane\", parent=\"harry\")\n",
    "tree.create_node(\"Bill\", \"bill\", parent=\"harry\")\n",
    "tree.create_node(\"Diane\", \"diane\", parent=\"jane\")\n",
    "tree.create_node(\"Mary\", \"mary\", parent=\"diane\")\n",
    "tree.create_node(\"Mark\", \"mark\", parent=\"jane\")\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztE3vNIlCDrS"
   },
   "source": [
    "The *height* or *depth* of a tree is the length of its longest branch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hR2ttvoICQDQ",
    "outputId": "c2d9ec9f-50f5-4cdf-9ebe-a3a4eac8c3d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_R1kZ0-A9a2"
   },
   "source": [
    "Notice how trees are made of subtrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_tTbcosBAfM",
    "outputId": "843f026e-24ca-451b-ba30-53cc89670eb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diane\n",
      "└── Mary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub_t = tree.subtree('diane')\n",
    "sub_t.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVrgFhk8Bapi"
   },
   "source": [
    "They might be manipulated in all sorts of ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8YupmnZBSdi",
    "outputId": "e282979a-82a8-45f6-f385-2e6850d0552f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry\n",
      "├── Jane\n",
      "│   ├── Diane\n",
      "│   └── Mark\n",
      "└── Mary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree.move_node('mary', 'harry')\n",
    "tree.remove_node('bill')\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxsJJGnXCuL8"
   },
   "source": [
    "Most the trees you will encounter do not have this pretty `show()` method. Instead, you will typically use a command like this to visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VdExKXLBCurJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"{\\\"Harry\\\": {\\\"children\\\": [{\\\"Jane\\\": {\\\"children\\\": [\\\"Diane\\\", \\\"Mark\\\"]}}, \\\"Mary\\\"]}}\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(tree.to_json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-Gn1QrFE3w6"
   },
   "source": [
    "**Exercise.**\n",
    "\n",
    "\n",
    "1.   Define a class `MyTree` having attributes `name` and `children`, where `children` is to be a list of `MyTree`. \n",
    "2.   Provide the constructor method `__init__(...)`, which takes the name of the node as parameter.  \n",
    "3.   Provide an `add_child(...)` method, so that if `p` and `c` are of type `MyTree`, then `p.add_child(c)` adds `c` within the children of `p`.\n",
    "4.   Use your methods to build an example tree of depth 2, and work at a quick and dirty way to visualize it. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTree:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.children = []\n",
    "        \n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "        \n",
    "    def visualize(self, indentation=0):\n",
    "        print(self.name)\n",
    "        for child in self.children:\n",
    "            print('\\t'*indentation + \" |-> \", end=\"\")\n",
    "            child.visualize(indentation+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent\n",
      " |-> child_a\n",
      "\t |-> child_aa\n",
      "\t |-> child_ab\n",
      " |-> child_b\n"
     ]
    }
   ],
   "source": [
    "parent = MyTree(\"parent\")\n",
    "child_a = MyTree(\"child_a\")\n",
    "child_b = MyTree(\"child_b\")\n",
    "child_aa = MyTree(\"child_aa\")\n",
    "child_ab = MyTree(\"child_ab\")\n",
    "\n",
    "child_a.add_child(child_aa)\n",
    "child_a.add_child(child_ab)\n",
    "parent.add_child(child_a)\n",
    "parent.add_child(child_b)\n",
    "\n",
    "parent.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh4bDwyRame7"
   },
   "source": [
    "## Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgcNTsEvWArc"
   },
   "source": [
    "During the lecture we gave several plausible mathematical definitions of what a computer is. One of them was that of *finite automata*. We were able characterize the set of problems that they are able to solve: they recognize *regular languages* i.e. those expressed by *regular expressions*. \n",
    "\n",
    "Later, we came to the conclusion that finite automata are quite a limited model of computation, and came to prefer *Turing machines* instead. \n",
    "\n",
    "Still, finite automata are used everywhere in Computer Science:\n",
    "*    in order to provide finitary desciption of computer systems, so as to prove properties about them (this is called *model checking*). \n",
    "*    in order to pattern match and manipulate strings efficiently, as expressed through regular expressions. \n",
    "\n",
    "The second use case is extremely common in practice. Let us play with it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2NEqJREZTDw"
   },
   "source": [
    "First we import the corresponding library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "agS14BacZZpY"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qi8bGrtfZeqh"
   },
   "source": [
    "Let us have a sample text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "okHGxSGnZkCg"
   },
   "outputs": [],
   "source": [
    "text = \"This is a string with term1, but it does not have the other term. Just term1, really.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptdIDScHZr3b"
   },
   "source": [
    "We now test whether a pattern is present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LoSbgWNXbt2i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"term2\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cJANDwdsZwqu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term1', 'term1']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"term1\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUJ3Rfa1anxp"
   },
   "source": [
    "Here is where the first occurence was found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eR4W5SGsarkY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(22, 27), match='term1'>\n",
      "22\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "match=re.search(\"term1\",text)\n",
    "print(match)\n",
    "print(match.start())\n",
    "print(match.end())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptQ-9hi8c-st"
   },
   "source": [
    "**Exercice.** Informally describe an algorithm, that searches for a string, within another. Come to the conclusion that this will be quite a bit of work, and come to appreciate the power of the regular expression module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "Let say we search for string A in string B. Let say we have a pointer (or letter number) nA=0 and mA=0 in A and nB=0 in B.\n",
    "\n",
    "Here is the algorithm:\n",
    " - If the mA-th letter of A matches with the nB-th letter of B, then we increment mA and nB.\n",
    " - If it doesn't match, then we increment nA, set nB=0, and set mA=nA.\n",
    " - If nB arrives at the end of B, then B is found in A starting at the nA-th letter of A.\n",
    " - If nA (or mA) arrives at the end of A, the B is not found in A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4-l9JWBdslD"
   },
   "source": [
    "On a daily basis, programmers need to do things such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4ODEV2g8Z9lh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type your email address :joseph.2a.37.33@gmail.com\n",
      "I see, so your provider is gmail.com ...\n"
     ]
    }
   ],
   "source": [
    "email=input(\"Please type your email address :\")\n",
    "domain=(re.split(\"@\",email))[1]\n",
    "print(\"I see, so your provider is\",domain,\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3Mw0FOEZMGV"
   },
   "source": [
    "Let us create a function that will print out results of searching for different patterns within a single text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5IVjR6QofWyN"
   },
   "outputs": [],
   "source": [
    "def mfindall(patterns,text):\n",
    "    '''\n",
    "    Takes in a list of regex patterns\n",
    "    Prints a list of all matches\n",
    "    '''\n",
    "    for pattern in patterns:\n",
    "        print(\"Searching for :\",pattern)\n",
    "        print(re.findall(pattern,text))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oui2apNlgCVV"
   },
   "source": [
    "*Repetitions.*\n",
    "1.    A character followed by the meta-character `*` is allowed  to be repeated zero or more times. \n",
    "2.    Using `+` means the character must appear at least once. \n",
    "3.    Using `?` means the character must appear zero or one time. \n",
    "4.    Using `{m}` means the character must appear `m` times. \n",
    "5.    Using `{m,n}` means the character must appear `m` to `n` times. Leaving out `n`, as in  `{m,}` means the value appears at least `m` times, with no maximum.\n",
    "\n",
    "When a match is encountered, python tries to make it as big as possible.\n",
    "    \n",
    "Try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SJCTT-qgqjU",
    "outputId": "5f1d4462-312f-4e90-f145-72960d87cb11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for : sd*\n",
      "['sd', 'sd', 's', 's', 'sddd', 'sddd', 'sddd', 'sd', 's', 's', 's', 's', 's', 's', 'sdddd']\n",
      "\n",
      "Searching for : sd+\n",
      "['sd', 'sd', 'sddd', 'sddd', 'sddd', 'sd', 'sdddd']\n",
      "\n",
      "Searching for : sd?\n",
      "['sd', 'sd', 's', 's', 'sd', 'sd', 'sd', 'sd', 's', 's', 's', 's', 's', 's', 'sd']\n",
      "\n",
      "Searching for : sd{3}\n",
      "['sddd', 'sddd', 'sddd', 'sddd']\n",
      "\n",
      "Searching for : sd{2,3}\n",
      "['sddd', 'sddd', 'sddd', 'sddd']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"sdsd..sssddd...sdddsddd...dsds...dsssss...sdddd\"\n",
    "\n",
    "patterns =     [ 'sd*',         # s followed by zero or more d's\n",
    "                'sd+',          # s followed by one or more d's\n",
    "                'sd?',          # s followed by zero or one d's\n",
    "                'sd{3}',        # s followed by three d's\n",
    "                'sd{2,3}',      # s followed by two to three d's\n",
    "                ]\n",
    "\n",
    "mfindall(patterns,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zR0qUadyhOz0"
   },
   "source": [
    "*Character sets.* `[...]` will match any single character in the square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JCIeCrePhnxx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for : [sd]\n",
      "['s', 'd', 's', 'd', 's', 's', 's', 'd', 'd', 'd', 's', 'd', 'd', 'd', 's', 'd', 'd', 'd', 'd', 's', 'd', 's', 'd', 's', 's', 's', 's', 's', 's', 'd', 'd', 'd', 'd']\n",
      "\n",
      "Searching for : s[sd]+\n",
      "['sdsd', 'sssddd', 'sdddsddd', 'sds', 'sssss', 'sdddd']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'sdsd..sssddd...sdddsddd...dsds...dsssss...sdddd'\n",
    "\n",
    "patterns = [ '[sd]',    # either s or d\n",
    "            's[sd]+']   # s followed by one or more s or d\n",
    "            \n",
    "\n",
    "mfindall(patterns,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVtzhx1FiZcy"
   },
   "source": [
    "*Exclusion.* `[^...]` will match any single character not in the brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-wA1xSm8jN3E"
   },
   "outputs": [],
   "source": [
    "text= 'This is a string! But it has punctuation. How can we remove it?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "azB5YHv8jUQz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'string', 'But', 'it', 'has', 'punctuation', 'How', 'can', 'we', 'remove', 'it']\n"
     ]
    }
   ],
   "source": [
    "l=re.findall('[^!.? ]+',text)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3r4hTUckg8W"
   },
   "source": [
    "Don't forget your functionnal programming skills:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kKfJstygjutk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This is a string But it has punctuation How can we remove it'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "reduce(lambda x,y: x+\" \"+y, l, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNlYY2zilUJo"
   },
   "source": [
    "*Character Ranges.*\n",
    "The format used is `[start-end]`. For instance `[a-f]` would return matches with any instance of letters between `a` and `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-X-csezLltJB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for : [a-z]+\n",
      "['his', 'is', 'an', 'example', 'sentence', 'ets', 'see', 'if', 'we', 'can', 'find', 'some', 'letters']\n",
      "\n",
      "Searching for : [A-Z]+\n",
      "['T', 'L']\n",
      "\n",
      "Searching for : [a-zA-Z]+\n",
      "['This', 'is', 'an', 'example', 'sentence', 'Lets', 'see', 'if', 'we', 'can', 'find', 'some', 'letters']\n",
      "\n",
      "Searching for : [A-Z][a-z]+\n",
      "['This', 'Lets']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'This is an example sentence. Lets see if we can find some letters.'\n",
    "\n",
    "patterns=     [ '[a-z]+',      # sequences of lower case letters\n",
    "                '[A-Z]+',      # sequences of upper case letters\n",
    "                '[a-zA-Z]+',   # sequences of lower or upper case letters\n",
    "                '[A-Z][a-z]+'] # one upper case letter followed by lower case letters\n",
    "                \n",
    "mfindall(patterns,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dgR5TSDk98c"
   },
   "source": [
    "*Escape Codes.*\n",
    "\n",
    "\n",
    "`^` refers to the beginning of the line. \n",
    "\n",
    "`$` refers to the end.\n",
    "\n",
    "`.` refers to any character. `\\.` refers to a dot. So does `[.]`.\n",
    "\n",
    "Moreover:\n",
    "<table border=\"1\" class=\"docutils\">\n",
    "<colgroup>\n",
    "<col width=\"14%\" />\n",
    "<col width=\"86%\" />\n",
    "</colgroup>\n",
    "<thead valign=\"bottom\">\n",
    "<tr class=\"row-odd\"><th class=\"head\">Code</th>\n",
    "<th class=\"head\">Meaning</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td><tt class=\"docutils literal\"><span class=\"pre\">\\d</span></tt></td>\n",
    "<td>a digit</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><tt class=\"docutils literal\"><span class=\"pre\">\\D</span></tt></td>\n",
    "<td>a non-digit</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><tt class=\"docutils literal\"><span class=\"pre\">\\s</span></tt></td>\n",
    "<td>whitespace (tab, space, newline, etc.)</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><tt class=\"docutils literal\"><span class=\"pre\">\\S</span></tt></td>\n",
    "<td>non-whitespace</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><tt class=\"docutils literal\"><span class=\"pre\">\\w</span></tt></td>\n",
    "<td>alphanumeric</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><tt class=\"docutils literal\"><span class=\"pre\">\\W</span></tt></td>\n",
    "<td>non-alphanumeric</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Escapes are indicated by prefixing the character with a backslash. Unfortunately, a backslash must itself be escaped in normal Python strings, and that results in expressions that are very difficult to read. Using raw strings, created by prefixing the literal value with `r`, eliminates this problem and maintains readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UrHc5Pgymc3G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for : \\d+\n",
      "['1233']\n",
      "\n",
      "Searching for : \\D+\n",
      "['This is a string with some numbers ', ' and a symbol #hashtag']\n",
      "\n",
      "Searching for : \\s+\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "\n",
      "Searching for : \\S+\n",
      "['This', 'is', 'a', 'string', 'with', 'some', 'numbers', '1233', 'and', 'a', 'symbol', '#hashtag']\n",
      "\n",
      "Searching for : \\w+\n",
      "['This', 'is', 'a', 'string', 'with', 'some', 'numbers', '1233', 'and', 'a', 'symbol', 'hashtag']\n",
      "\n",
      "Searching for : \\W+\n",
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' #']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'This is a string with some numbers 1233 and a symbol #hashtag'\n",
    "\n",
    "patterns =      [ r'\\d+', # sequence of digits\n",
    "                r'\\D+', # sequence of non-digits\n",
    "                r'\\s+', # sequence of whitespace\n",
    "                r'\\S+', # sequence of non-whitespace\n",
    "                r'\\w+', # alphanumeric characters\n",
    "                r'\\W+', # non-alphanumeric\n",
    "                ]\n",
    "\n",
    "mfindall(patterns,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hmbw3LJo8T3"
   },
   "source": [
    "Regular expressions are faster when compiled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bQd3xbMxpAf-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guido@python.org', 'guido@google.com']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"To email Guido, try guido@python.org or the older address guido@google.com.\"\n",
    "email = re.compile(r'\\w+@\\w+\\.[a-z]{3}')\n",
    "email.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etElS0TUpSaN"
   },
   "source": [
    "They provide fast mechanisms for find/replace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "wlgDZll_pcx3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To email Guido, try xxx@xxx.xxx or the older address xxx@xxx.xxx.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email.sub(\"xxx@xxx.xxx\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87XXJISbrUmf"
   },
   "source": [
    "The above does not quite work however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CBtBhdxfrZa6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obama@whitehouse.gov']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email.findall('barack.obama@whitehouse.gov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyDrLzper4SB"
   },
   "source": [
    "**Exercise.** Write an `email2` regexp so it does not drop the first name in the above example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barack.obama@whitehouse.gov']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email2 = re.compile(r'[\\w+.+]+@\\w+\\.[a-z]{3}')\n",
    "email2.findall('barack.obama@whitehouse.gov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qK5cX9du4Td"
   },
   "source": [
    "**Exercise.** Write an `ip` regexp which matches IP addresses. Assume `ipv4` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(16, 29), match='129.154.20.34'>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = re.compile(r'(\\d{1,3}\\.){3}\\d{1,3}')\n",
    "text = \"my IP adress is 129.154.20.34\"\n",
    "ip.search(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9P_WdNRtRScl",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "*Groups.* Parentheses indicate groups to extract. We often want to extract their components rather than the full match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "JbMYQ5BRRScl",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "email3 = re.compile(r'([\\w.]+)@(\\w+)\\.([a-z]{3})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5W19YIzRScl",
    "outputId": "84fdb8fe-7d07-4062-8375-d51db4348113",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guido', 'python', 'org'), ('guido', 'google', 'com')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"To email Guido, try guido@python.org or the older address guido@google.com.\"\n",
    "email3.findall(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYFzCkDbBDZM"
   },
   "source": [
    "If you'd rather see the full match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5d5vLg048J0C",
    "outputId": "a8e04b5b-e7ae-4448-82d8-6b8aea9661ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'guido@python.org'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email3.search(text).group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TgpL089zAuA"
   },
   "source": [
    "We can use previously extracted groups to match repetions of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngFcLBcLy_Qv",
    "outputId": "49deb66c-c3bf-4c97-f630-aca067b35bc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(23, 27), match='abab'>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"nnabnnnnnnnnnnnnnnnnnnnababababababnnnnnnnnnaaaaabbbnnnnnnnnnnnnn\"\n",
    "myreg=re.compile(r'(ab)\\1')\n",
    "myreg.search(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjLtu5kN89UW"
   },
   "source": [
    "Equivalently we could have written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5Y22pXI9LF-",
    "outputId": "5efbfaf4-3bff-4038-b8f2-3255d1617202"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(23, 27), match='abab'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"nnabnnnnnnnnnnnnnnnnnnnababababababnnnnnnnnnaaaaabbbnnnnnnnnnnnnn\"\n",
    "myreg=re.compile(r'(ab){2}')\n",
    "myreg.search(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcdOd9vG9gVB"
   },
   "source": [
    "Finally, we can use `|` as an or operator, between expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3tj1_Bp9sGJ",
    "outputId": "e4980eb7-9aed-4d63-9e8f-ee1a6e4e3dbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(1, 5), match='nabn'>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"nnabnnnnnnnnnnnnnnnnnnnababababababnnnnnnnnnaaaaabbbnnnnnnnnnnnnn\"\n",
    "myreg=re.compile(r'((ab){2})|nabn')\n",
    "myreg.search(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM5tPSho91do"
   },
   "source": [
    "**Exercise.** Extend the previous expression that matched `ipv4`, to also match `ipv6` addresses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(16, 55), match='2001:0db8:3333:4444:5555:6666:7777:8888'>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip2 = re.compile(r'(([0-9a-f]{1,4}\\:)+[0-9a-f]{1,4})|(\\d{1,3}\\.){3}\\d{1,3}')\n",
    "text = 'my IP adress is 2001:0db8:3333:4444:5555:6666:7777:8888 and not 129.154.20.34'\n",
    "ip2.search(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGgdmTC2nFwh"
   },
   "source": [
    "*References.* There are [many more things](https://docs.python.org/2/library/re.html#regular-expression-syntax) you can do with regular expressions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnsKkdcaMfid"
   },
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqkwqizZUAUt"
   },
   "source": [
    "Regular expressions describe regular languages. Regular languages were discussed, at the theoretical-level during the lectures. They are an interesting, but nevertheless simple class of languages. \n",
    "\n",
    "The aim of this section is to teach you how to describe more complicated languages, such as programming languages. Programming languages were again discussed at the theoretical-level during the lectures, in terms of their grammar and semantics. \n",
    "\n",
    "This section will deal with language grammars, and semantics, at the practical level. We will rely on a library called `Tatsu` in order to :\n",
    "1.   Describe language grammars.\n",
    "2.   Recognize whether a given text obeys the grammar.\n",
    "3.   *Parse* the text according to the grammar. \n",
    "4.   Provide semantics to the language.\n",
    "5.   Translate the language into another. \n",
    "\n",
    "When a computer parses a text according to a grammar, it creates a tree-like data structure in memory, that represents the text in a well-organized manner. It is the computer's way of \"understanding the text\" and \"keeping it in mind in an orderly fashion\".  \n",
    "\n",
    "When we provide a semantics for the language, we are telling the computer what to make of that tree-like representation of the text. For instance, if the language is progamming language, the tree represents a text which is a program, which the computer ought to execute. So, the semantics tells the computer how to take actions according to the content of that tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fngWvA3vaREa"
   },
   "source": [
    "So, let us install the `Tatsu` library. Its documentation is [here](https://tatsu.readthedocs.io/en/stable/).\n",
    "\n",
    "By-the-way, there are many other such libraries, nicely reviewed [here](https://tomassetti.me/parsing-in-python/). Another mainstream choice could have been the `Lark` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oigd7T5ci27e",
    "outputId": "b096f40a-5780-47cf-e7c7-24f2341ae5e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tatsu in /home/joseph/.local/lib/python3.10/site-packages (5.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tatsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNuVVP-caY1o"
   },
   "source": [
    "Let us import the library so we can use it. We also take this opportunity to give a short nickname to some of the trees generated by `tatsu`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "prkWiea3RFuM"
   },
   "outputs": [],
   "source": [
    "import tatsu\n",
    "from tatsu.ast import AST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ETgDPoAaeoW"
   },
   "source": [
    "These two will come as handy in order to visualize some of trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "sYhoySyCi5sa"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hn2-2ztdcGUm"
   },
   "source": [
    "Our first custom language will be a language of arithmetic expressions.\n",
    "\n",
    "We must first describe its grammar. The grammar of will be described according some conventions... i.e. according to a \"language to describe language grammars\"! \n",
    "\n",
    "There are several such metalanguages. This one is called EBNF. It is quite standard, powerful, and looks a lot like the way we described grammars during the lectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "UyKDkp7zQN7w"
   },
   "outputs": [],
   "source": [
    "grammar=\"\"\"\n",
    "@@grammar::CALC\n",
    "\n",
    "\n",
    "start\n",
    "    =\n",
    "    expression $\n",
    "    ;\n",
    "\n",
    "\n",
    "expression\n",
    "    =\n",
    "    | expression '+' term\n",
    "    | expression '-' term\n",
    "    | term\n",
    "    ;\n",
    "\n",
    "\n",
    "term\n",
    "    =\n",
    "    | term '*' factor\n",
    "    | term '/' factor\n",
    "    | factor\n",
    "    ;\n",
    "\n",
    "\n",
    "factor\n",
    "    =\n",
    "    | '(' expression ')'\n",
    "    | number\n",
    "    ;\n",
    "\n",
    "\n",
    "number\n",
    "    =\n",
    "    /\\d+/\n",
    "    ;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmSZfvDyefgd"
   },
   "source": [
    "Some comments are in order:\n",
    "```\n",
    "start\n",
    "    =\n",
    "    expression $\n",
    "    ;\n",
    "```\n",
    "says that a text starts (`start`) with an expression and ends (`$`) there. \n",
    "\n",
    "\n",
    "Expressions may contain sums, so:\n",
    "```\n",
    "expression\n",
    "    =\n",
    "    | expression '+' term\n",
    "    | expression '-' term\n",
    "    | term\n",
    "    ;\n",
    "```\n",
    "says an expression is an expression plus/minus a term, or just a term. \n",
    "\n",
    "Terms may contain products, so:\n",
    "```\n",
    "term\n",
    "    =\n",
    "    | term '*' factor\n",
    "    | term '/' factor\n",
    "    | factor\n",
    "    ;\n",
    "```\n",
    "says an expression is an expression times/divided by a factor, or just a factor. \n",
    "\n",
    "Factors may contain numbers or bracketted expressions:\n",
    "```\n",
    "factor\n",
    "    =\n",
    "    | '(' expression ')'\n",
    "    | number\n",
    "    ;\n",
    "\n",
    "number\n",
    "    =\n",
    "    /\\d+/\n",
    "    ;\n",
    "```\n",
    "Notice how numbers are described: just by a regular expression in between `/.../`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WtzOdNJgrNy"
   },
   "source": [
    "Let us tell `tatsu` to create a parser for that grammar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "slJwe6W7gyuj"
   },
   "outputs": [],
   "source": [
    "parser = tatsu.compile(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujcyY4X5g600"
   },
   "source": [
    "This parser can be used to check whether some text obeys the language grammar.\n",
    "\n",
    "For instance, this does not work because it is not within our language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "pgO1j-H1hwpo"
   },
   "outputs": [
    {
     "ename": "FailedLeftRecursion",
     "evalue": "(1:1) infinite left recursion :\nHello\n^\nexpression\nstart",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedLeftRecursion\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [153], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:1091\u001b[0m, in \u001b[0;36mGrammar.parse\u001b[0;34m(self, text, config, ctx, **settings)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1090\u001b[0m     ctx \u001b[38;5;241m=\u001b[39m ModelContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrules, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:239\u001b[0m, in \u001b[0;36mParseContext.parse\u001b[0;34m(self, text, config, **settings)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FailedParse \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_furthest_exception(e)\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_furthest_exception\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_memoization_caches()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:232\u001b[0m, in \u001b[0;36mParseContext.parse\u001b[0;34m(self, text, config, **settings)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     rule \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_rule(start)\n\u001b[0;32m--> 232\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FailedCut \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:880\u001b[0m, in \u001b[0;36mRule.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 880\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_rhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:892\u001b[0m, in \u001b[0;36mRule._parse_rhs\u001b[0;34m(self, ctx, exp)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_rhs\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx, exp):\n\u001b[1;32m    884\u001b[0m     ruleinfo \u001b[38;5;241m=\u001b[39m RuleInfo(\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, exp\u001b[38;5;241m.\u001b[39mparse,\n\u001b[1;32m    886\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leftrec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwparams\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruleinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:613\u001b[0m, in \u001b[0;36mParseContext._call\u001b[0;34m(self, ruleinfo)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_entry()\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruleinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m node, newpos, newstate \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_goto(newpos)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:641\u001b[0m, in \u001b[0;36mParseContext._recursive_call\u001b[0;34m(self, ruleinfo)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recursive_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, ruleinfo):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ruleinfo\u001b[38;5;241m.\u001b[39mis_leftrec:\n\u001b[0;32m--> 641\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_rule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruleinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemokey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_recursion:\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLeft recursion detected\u001b[39m\u001b[38;5;124m'\u001b[39m, exclass\u001b[38;5;241m=\u001b[39mFailedLeftRecursion)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:690\u001b[0m, in \u001b[0;36mParseContext._invoke_rule\u001b[0;34m(self, ruleinfo, key)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_token(ruleinfo)\n\u001b[0;32m--> 690\u001b[0m     \u001b[43mruleinfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node(key\u001b[38;5;241m.\u001b[39mpos, ruleinfo)\n\u001b[1;32m    692\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_semantic_rule(ruleinfo, node)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:458\u001b[0m, in \u001b[0;36mSequence.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 458\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mlast_node \u001b[38;5;241m=\u001b[39m [s\u001b[38;5;241m.\u001b[39mparse(ctx) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence]\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mlast_node\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:458\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 458\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mlast_node \u001b[38;5;241m=\u001b[39m [\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence]\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mlast_node\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:825\u001b[0m, in \u001b[0;36mRuleRef.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    823\u001b[0m     ctx\u001b[38;5;241m.\u001b[39m_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, exclass\u001b[38;5;241m=\u001b[39mFailedRef)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:880\u001b[0m, in \u001b[0;36mRule.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 880\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_rhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:892\u001b[0m, in \u001b[0;36mRule._parse_rhs\u001b[0;34m(self, ctx, exp)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_rhs\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx, exp):\n\u001b[1;32m    884\u001b[0m     ruleinfo \u001b[38;5;241m=\u001b[39m RuleInfo(\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, exp\u001b[38;5;241m.\u001b[39mparse,\n\u001b[1;32m    886\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leftrec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwparams\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruleinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:613\u001b[0m, in \u001b[0;36mParseContext._call\u001b[0;34m(self, ruleinfo)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_entry()\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruleinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m node, newpos, newstate \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_goto(newpos)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:674\u001b[0m, in \u001b[0;36mParseContext._recursive_call\u001b[0;34m(self, ruleinfo)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recursion_depth \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m result  \u001b[38;5;66;03m# pylint: disable=raising-non-exception\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:784\u001b[0m, in \u001b[0;36mParseContext._option\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try():\n\u001b[0;32m--> 784\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionSucceeded()\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FailedCut:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:522\u001b[0m, in \u001b[0;36mChoice.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39m_option():\n\u001b[0;32m--> 522\u001b[0m         ctx\u001b[38;5;241m.\u001b[39mlast_node \u001b[38;5;241m=\u001b[39m \u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mlast_node\n\u001b[1;32m    525\u001b[0m lookahead \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookahead_str()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:576\u001b[0m, in \u001b[0;36mOption.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 576\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_defined_attributes(ctx, result)\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:271\u001b[0m, in \u001b[0;36mDecorator.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:458\u001b[0m, in \u001b[0;36mSequence.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 458\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mlast_node \u001b[38;5;241m=\u001b[39m [s\u001b[38;5;241m.\u001b[39mparse(ctx) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence]\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mlast_node\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:458\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 458\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mlast_node \u001b[38;5;241m=\u001b[39m [\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence]\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mlast_node\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:825\u001b[0m, in \u001b[0;36mRuleRef.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    823\u001b[0m     ctx\u001b[38;5;241m.\u001b[39m_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, exclass\u001b[38;5;241m=\u001b[39mFailedRef)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:880\u001b[0m, in \u001b[0;36mRule.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 880\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_rhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:892\u001b[0m, in \u001b[0;36mRule._parse_rhs\u001b[0;34m(self, ctx, exp)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_rhs\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx, exp):\n\u001b[1;32m    884\u001b[0m     ruleinfo \u001b[38;5;241m=\u001b[39m RuleInfo(\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, exp\u001b[38;5;241m.\u001b[39mparse,\n\u001b[1;32m    886\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leftrec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwparams\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruleinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:613\u001b[0m, in \u001b[0;36mParseContext._call\u001b[0;34m(self, ruleinfo)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_entry()\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruleinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m node, newpos, newstate \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_goto(newpos)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:674\u001b[0m, in \u001b[0;36mParseContext._recursive_call\u001b[0;34m(self, ruleinfo)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recursion_depth \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m result  \u001b[38;5;66;03m# pylint: disable=raising-non-exception\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:784\u001b[0m, in \u001b[0;36mParseContext._option\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try():\n\u001b[0;32m--> 784\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionSucceeded()\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FailedCut:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:522\u001b[0m, in \u001b[0;36mChoice.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39m_option():\n\u001b[0;32m--> 522\u001b[0m         ctx\u001b[38;5;241m.\u001b[39mlast_node \u001b[38;5;241m=\u001b[39m \u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mlast_node\n\u001b[1;32m    525\u001b[0m lookahead \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookahead_str()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:576\u001b[0m, in \u001b[0;36mOption.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 576\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_defined_attributes(ctx, result)\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:271\u001b[0m, in \u001b[0;36mDecorator.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:458\u001b[0m, in \u001b[0;36mSequence.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 458\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mlast_node \u001b[38;5;241m=\u001b[39m [s\u001b[38;5;241m.\u001b[39mparse(ctx) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence]\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mlast_node\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:458\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 458\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mlast_node \u001b[38;5;241m=\u001b[39m [\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence]\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mlast_node\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:825\u001b[0m, in \u001b[0;36mRuleRef.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    823\u001b[0m     ctx\u001b[38;5;241m.\u001b[39m_error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, exclass\u001b[38;5;241m=\u001b[39mFailedRef)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:880\u001b[0m, in \u001b[0;36mRule.parse\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[0;32m--> 880\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_rhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/grammars.py:892\u001b[0m, in \u001b[0;36mRule._parse_rhs\u001b[0;34m(self, ctx, exp)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_rhs\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx, exp):\n\u001b[1;32m    884\u001b[0m     ruleinfo \u001b[38;5;241m=\u001b[39m RuleInfo(\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, exp\u001b[38;5;241m.\u001b[39mparse,\n\u001b[1;32m    886\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leftrec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwparams\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruleinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:613\u001b[0m, in \u001b[0;36mParseContext._call\u001b[0;34m(self, ruleinfo)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_entry()\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruleinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m node, newpos, newstate \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_goto(newpos)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tatsu/contexts.py:674\u001b[0m, in \u001b[0;36mParseContext._recursive_call\u001b[0;34m(self, ruleinfo)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recursion_depth \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m result  \u001b[38;5;66;03m# pylint: disable=raising-non-exception\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mFailedLeftRecursion\u001b[0m: (1:1) infinite left recursion :\nHello\n^\nexpression\nstart"
     ]
    }
   ],
   "source": [
    "parser.parse(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hgI_xyfiBYp"
   },
   "source": [
    "But this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "VSKN5CIuhQRc",
    "outputId": "43092729-6e73-4048-d9e4-92afec30a32d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEL3fOP5hW_5",
    "outputId": "c87d6d8a-ac6e-4589-cbf5-4d925a6d3df4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3', '+', '2')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse(\"3+2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6_8dpWUheRO",
    "outputId": "4f7c25ea-f298-4418-fcaf-45dced694dfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('(', ('3', '+', '2'), ')'), '*', '4')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse(\"(3+2)*4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0o-RTn-iJv2"
   },
   "source": [
    "Let us parse a more complicated expression, and visualize the resulting tree-like structure in a nicer way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1pFmGsNN1UH",
    "outputId": "b056b93e-87f0-4a52-c287-9cf031e2b24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(   (   '5',\n",
      "        '*',\n",
      "        (   '(',\n",
      "            (   '1',\n",
      "                '-',\n",
      "                '2'),\n",
      "            ')')),\n",
      "    '+',\n",
      "    (   '50',\n",
      "        '*',\n",
      "        (   '(',\n",
      "            (   '10',\n",
      "                '-',\n",
      "                '20'),\n",
      "            ')')))\n"
     ]
    }
   ],
   "source": [
    "ast = parser.parse(\"5 * (1-2) + 50 * ( 10 - 20 )\")\n",
    "print(type(ast))\n",
    "pprint(ast, width=20, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7aUCwfEik1d"
   },
   "source": [
    "We see that the parser is indeed returning a tree-like structure.\n",
    "*   The root of the tree is `+`\n",
    "*   It has too branches whose roots are `*`\n",
    "*   Those have leafs `3` and `5`, but also more branches, etc.\n",
    "\n",
    "Tree-like representations of languages as generated by parsers are referred to as *abstract syntax trees*---which is why we chose to call our variable `ast`.\n",
    "\n",
    "Technically this particular `ast` is just a list, though. \n",
    "We may wish for a more informative tree-like structure, for instance one that tags `op` in front of an operation whenever it finds one. This is what the following, annotated grammar will produce:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "Egu67LKyRfK5"
   },
   "outputs": [],
   "source": [
    "grammar=\"\"\"\n",
    "@@grammar::CALC\n",
    "\n",
    "\n",
    "start\n",
    "    =\n",
    "    expression $\n",
    "    ;\n",
    "\n",
    "\n",
    "expression\n",
    "    =\n",
    "    | left:expression op:'+' right:term\n",
    "    | left:expression op:'-' right:term\n",
    "    | term\n",
    "    ;\n",
    "\n",
    "\n",
    "term\n",
    "    =\n",
    "    | left:term op:'*' right:factor\n",
    "    | left:term '/' right:factor\n",
    "    | factor\n",
    "    ;\n",
    "\n",
    "\n",
    "factor\n",
    "    =\n",
    "    | '(' @:expression ')'\n",
    "    | number\n",
    "    ;\n",
    "\n",
    "\n",
    "number\n",
    "    =\n",
    "    /\\d+/\n",
    "    ;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7J3qsy7vmmZC"
   },
   "source": [
    "Some comments: \n",
    "```\n",
    "op:'*'\n",
    "```\n",
    "will tag the occurrence of `*` with `op`. \n",
    "```\n",
    "@:\n",
    "```\n",
    "will skip the surrounding parentheses in the abstract syntax tree production, resulting in a simpler, more readable tree. \n",
    "\n",
    "Indeed, notice that parentheses are only useful in the text version of the expressions, in order to lift ambiguities. But the tree-like structure has lifted those ambiguities already, so it does not need to hold cumbersome parentheses.\n",
    "\n",
    "Notice that the resulting abstract syntax tree is no longer a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYcoMXYyN83A",
    "outputId": "8db6c0b9-c127-4bd2-ef68-88a5fba9cda5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tatsu.ast.AST'>\n",
      "{'left': {'left': '5', 'op': '*', 'right': {'left': '1', 'op': '-', 'right': '2'}}, 'op': '+', 'right': {'left': '50', 'op': '*', 'right': {'left': '10', 'op': '-', 'right': '20'}}}\n"
     ]
    }
   ],
   "source": [
    "parser = tatsu.compile(grammar)\n",
    "ast = parser.parse(\"5 * (1-2) + 50 * ( 10 - 20 )\")\n",
    "print(type(ast))\n",
    "pprint(ast, width=20, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bWj-tTVoUqL"
   },
   "source": [
    "This object can be navigated through its attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pliUd3Qeoa3G",
    "outputId": "52145be9-34b7-4046-bd0e-3cb813964169"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIV_s7c4oeEd",
    "outputId": "d2f86cc8-4263-4cf5-b5a8-81f60371b1e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left': '5', 'op': '*', 'right': {'left': '1', 'op': '-', 'right': '2'}}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4zbhYAblojcq",
    "outputId": "14203234-10a8-45e0-d996-86858014ed68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.left.op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOYDVQdaonei"
   },
   "source": [
    "**Exercise.** Navigate to the `10` that way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "4yBzhUwUo0LB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.right.right.left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9bAqsKJo6PV"
   },
   "source": [
    "So, we can parse arithmetic expressions now. \n",
    "\n",
    "Let us give them meaning, i.e. a semantics that says how to evaluate them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "SyL2VOc2ZBvt"
   },
   "outputs": [],
   "source": [
    "class CalcBasicSemantics(object):\n",
    "    def number(self, ast):\n",
    "        print(\"number\",ast)\n",
    "        return int(ast)\n",
    "\n",
    "    def term(self, ast):\n",
    "        print(\"term\",ast)\n",
    "        if not isinstance(ast, AST):\n",
    "            return ast\n",
    "        elif ast.op == '*':\n",
    "            return ast.left * ast.right\n",
    "        elif ast.op == '/':\n",
    "            return ast.left / ast.right\n",
    "        else:\n",
    "            raise Exception('Unknown operator', ast.op)\n",
    "\n",
    "    def expression(self, ast):\n",
    "        print(\"expression\",ast)\n",
    "        if  not isinstance(ast, AST):\n",
    "            return ast\n",
    "        elif ast.op == '+':\n",
    "            return ast.left + ast.right\n",
    "        elif ast.op == '-':\n",
    "            return ast.left - ast.right\n",
    "        else:\n",
    "            raise Exception('Unknown operator', ast.op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6TyoMWoVp8E",
    "outputId": "9a06aa18-8c95-4314-d412-7a4d18351d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'left': '3', 'op': '+', 'right': {'left': '5', 'op': '*', 'right': {'left': '10', 'op': '-', 'right': '20'}}}\n",
      "number 3\n",
      "term 3\n",
      "term 3\n",
      "expression 3\n",
      "number 5\n",
      "term 5\n",
      "number 10\n",
      "term 10\n",
      "term 10\n",
      "expression 10\n",
      "number 20\n",
      "term 20\n",
      "term 20\n",
      "expression {'left': 10, 'op': '-', 'right': 20}\n",
      "expression 10\n",
      "term {'left': 5, 'op': '*', 'right': -10}\n",
      "term 5\n",
      "expression {'left': 3, 'op': '+', 'right': -50}\n",
      "expression 3\n",
      "-------------\n",
      "-47\n"
     ]
    }
   ],
   "source": [
    "ast=parser.parse(\"3 + 5 * ( 10 - 20 )\")\n",
    "pprint(ast, width=20, indent=4)\n",
    "result = parser.parse(\"3 + 5 * ( 10 - 20 )\",semantics=CalcBasicSemantics())\n",
    "print(\"-------------\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSgmTI9GrXTm"
   },
   "source": [
    "**Exercise.** \n",
    "1.   Explain the order in which the prints get executed. Which [depth-first tree traversal order](https://en.wikipedia.org/wiki/Tree_traversal) is used? Why this choice? \n",
    "2.   Try without the `if not isinstance(ast,AST)`. Explain why it was there in the first place. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "1) We choose to traverse in a Depth-first search, i.e. a recursive manner, first to the left and then to the right. The reason is to \"collapse\" expression recursivly, because we can only apply operations to number and not operations.\n",
    "\n",
    "2) if we remove `if not isinstance(ast,AST)`, we get an error \"`'int' object has no attribute 'op'`\", because when `ast` is a number, we want to return it as is, as it is not an expression to be computed (it has no `op` attribute)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix-UrWyOubsW"
   },
   "source": [
    "These `isinstance(...)` and `elif ast.op==...` are not very nice, they make our semantics rather cumbersome. \n",
    "\n",
    "It turns out we can get rid of them, at the cost of a more fined-grained grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeEEblH_U9sf"
   },
   "outputs": [],
   "source": [
    "grammar =\"\"\"\n",
    "@@grammar::CALC\n",
    "\n",
    "start\n",
    "    =\n",
    "    expression $\n",
    "    ;\n",
    "\n",
    "\n",
    "expression\n",
    "    =\n",
    "    | addition\n",
    "    | subtraction\n",
    "    | term\n",
    "    ;\n",
    "\n",
    "\n",
    "addition\n",
    "    =\n",
    "    left:expression op:'+' ~ right:term\n",
    "    ;\n",
    "\n",
    "subtraction\n",
    "    =\n",
    "    left:expression op:'-' ~ right:term\n",
    "    ;\n",
    "\n",
    "\n",
    "term\n",
    "    =\n",
    "    | multiplication\n",
    "    | division\n",
    "    | factor\n",
    "    ;\n",
    "\n",
    "\n",
    "multiplication\n",
    "    =\n",
    "    left:term op:'*' ~ right:factor\n",
    "    ;\n",
    "\n",
    "\n",
    "division\n",
    "    =\n",
    "    left:term '/' ~ right:factor\n",
    "    ;\n",
    "\n",
    "\n",
    "factor\n",
    "    =\n",
    "    | '(' ~ @:expression ')'\n",
    "    | number\n",
    "    ;\n",
    "\n",
    "\n",
    "number\n",
    "    =\n",
    "    /\\d+/\n",
    "    ;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hf5IROxRU0Zw"
   },
   "outputs": [],
   "source": [
    "class CalcSemantics(object):\n",
    "    def number(self, ast):\n",
    "        print(\"number\",ast)\n",
    "        return int(ast)\n",
    "\n",
    "    def addition(self, ast):\n",
    "        print(\"addition\",ast)\n",
    "        return ast.left + ast.right\n",
    "\n",
    "    def subtraction(self, ast):\n",
    "        print(\"subtraction\",ast)\n",
    "        return ast.left - ast.right\n",
    "\n",
    "    def multiplication(self, ast):\n",
    "        print(\"multiplication\",ast)\n",
    "        return ast.left * ast.right\n",
    "\n",
    "    def division(self, ast):\n",
    "        print(\"division\",ast)\n",
    "        return ast.left / ast.right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3j1tvl2vUc0Z",
    "outputId": "2015172c-bc9c-4a43-d65c-1d2b5e7911fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'left': '3',\n",
      "    'op': '+',\n",
      "    'right': {   'left': '5',\n",
      "                 'op': '*',\n",
      "                 'right': {   'left': '10',\n",
      "                              'op': '-',\n",
      "                              'right': '20'}}}\n",
      "number 3\n",
      "number 5\n",
      "number 10\n",
      "number 20\n",
      "subtraction AST({'left': 10, 'op': '-', 'right': 20})\n",
      "multiplication AST({'left': 5, 'op': '*', 'right': -10})\n",
      "number 5\n",
      "addition AST({'left': 3, 'op': '+', 'right': -50})\n",
      "-------------\n",
      "-47\n"
     ]
    }
   ],
   "source": [
    "parser = tatsu.compile(grammar)\n",
    "ast=parser.parse(\"3 + 5 * ( 10 - 20 )\")\n",
    "pprint(ast, width=20, indent=4)\n",
    "result= parser.parse(\"3 + 5 * ( 10 - 20 )\",semantics=CalcSemantics())\n",
    "print(\"-------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymundbuax7TB"
   },
   "source": [
    "**Exercise.**  Explain how this solution manages to avoid `if` statements in the semantics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "This solutions avoids `if` statements in the semantics, by creating a separate gramatical class for each operator/entity so the semantics uses different functions for different operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmCoVunoykji"
   },
   "source": [
    "At this stage, the parser is generating an abstract syntax tree whose type is an object of type the `tatsu` pre-defined class AST: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0KYUYwpy5Cg"
   },
   "outputs": [],
   "source": [
    "type(ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5zikOAyzAQM"
   },
   "source": [
    "Their branches are themselves AST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8ObeHFqzSRg"
   },
   "outputs": [],
   "source": [
    "type(ast.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSUD2BqNzY4l"
   },
   "source": [
    "This is not bad, but we may prefer to have our custom objects forming the tree instead. For instance, this could be used as a way to retain the type of subexpression at hand, e.g. whether an addition, a multiplication...\n",
    "\n",
    "Further annotations in the grammar let you do this. Below, `::Add` specifies that a node of type `Add` should be used to represent that subexpression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "id": "NR4K2JMnZqlu"
   },
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "@@grammar::Calc\n",
    "\n",
    "\n",
    "start\n",
    "    =\n",
    "    expression $\n",
    "    ;\n",
    "\n",
    "\n",
    "expression\n",
    "    =\n",
    "    | addition\n",
    "    | subtraction\n",
    "    | term\n",
    "    ;\n",
    "\n",
    "\n",
    "addition::Add\n",
    "    =\n",
    "    left:term op:'+' ~ right:expression\n",
    "    ;\n",
    "\n",
    "\n",
    "subtraction::Subtract\n",
    "    =\n",
    "    left:term op:'-' ~ right:expression\n",
    "    ;\n",
    "\n",
    "\n",
    "term\n",
    "    =\n",
    "    | exponentiation\n",
    "    | multiplication\n",
    "    | division\n",
    "    | factor\n",
    "    ;\n",
    "\n",
    "exponentiation::Exponentiate\n",
    "    =\n",
    "    left:factor op:'**' ~ right:term\n",
    "    ;\n",
    "    \n",
    "multiplication::Multiply\n",
    "    =\n",
    "    left:factor op:'*' ~ right:term\n",
    "    ;\n",
    "\n",
    "\n",
    "division::Divide\n",
    "    =\n",
    "    left:factor '/' ~ right:term\n",
    "    ;\n",
    "\n",
    "\n",
    "factor\n",
    "    =\n",
    "    | subexpression\n",
    "    | number\n",
    "    ;\n",
    "\n",
    "\n",
    "subexpression\n",
    "    =\n",
    "    '(' ~ @:expression ')'\n",
    "    ;\n",
    "\n",
    "\n",
    "number::int\n",
    "    =\n",
    "    /\\d+/\n",
    "    ;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwQ42zfHZoE8",
    "outputId": "5440078a-9767-4e10-dd52-527c8db3f10c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add\n",
      "<class 'tatsu.synth.Add'>\n",
      "{\n",
      "    \"__class__\": \"Add\",\n",
      "    \"left\": 3,\n",
      "    \"right\": {\n",
      "        \"__class__\": \"Multiply\",\n",
      "        \"left\": 5,\n",
      "        \"right\": {\n",
      "            \"__class__\": \"Exponentiate\",\n",
      "            \"left\": {\n",
      "                \"__class__\": \"Subtract\",\n",
      "                \"left\": 10,\n",
      "                \"right\": 20,\n",
      "                \"op\": \"-\"\n",
      "            },\n",
      "            \"right\": 2,\n",
      "            \"op\": \"**\"\n",
      "        },\n",
      "        \"op\": \"*\"\n",
      "    },\n",
      "    \"op\": \"+\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parser = tatsu.compile(grammar, asmodel=True)\n",
    "ast = parser.parse(\"3 + 5 * ( 10 - 20 ) ** 2\")\n",
    "print(type(ast).__name__)\n",
    "print(type(ast))\n",
    "print(json.dumps(ast.asjson(), indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tvq1kbVY1o3k"
   },
   "source": [
    "Instead of directly evaluating our expressions as we would parse them, all-in-one-go as we did before, it is better practice to produce the abstract syntax tree, and then walk through the abstract syntax tree.\n",
    "\n",
    "One of the reasons for that is that the abstract syntax tree may require several traversals before being evaluated, e.g. \n",
    "for \n",
    "1.    *name analysis* i.e. understanding which occurence of a variable corresponds to which declaration.\n",
    "2.    *type checking* as in the lectures.\n",
    "3.    *linking* i.e. relating different modules.\n",
    "4.    *optimization* i.e. transforming the code to make it more efficient.\n",
    "\n",
    "A convenient way to walk through the abstract syntax tree is to use a Walker, i.e. an object that you define and that inherits from `tatsu.walkers.NodeWalker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "id": "D_2iPe-Fct_f"
   },
   "outputs": [],
   "source": [
    "from tatsu.walkers import NodeWalker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "id": "b6JjCyEfcsqj"
   },
   "outputs": [],
   "source": [
    "class CalcWalker(NodeWalker):\n",
    "    def walk_object(self, node):\n",
    "        print(\"Object\", node)\n",
    "        return node\n",
    "\n",
    "    def walk__add(self, node):\n",
    "        print(\"Add\")\n",
    "        return self.walk(node.left) + self.walk(node.right)\n",
    "\n",
    "    def walk__subtract(self, node):\n",
    "        print(\"Subtract\")\n",
    "        return self.walk(node.left) - self.walk(node.right)\n",
    "\n",
    "    def walk__multiply(self, node):\n",
    "        print(\"Multiply\")\n",
    "        return self.walk(node.left) * self.walk(node.right)\n",
    "\n",
    "    def walk__divide(self, node):\n",
    "        print(\"Divide\", node)\n",
    "        return self.walk(node.left) / self.walk(node.right)\n",
    "    \n",
    "    def walk__exponentiate(self, node):\n",
    "        print(\"Exponentiate\", node)\n",
    "        return self.walk(node.left) ** self.walk(node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pt3CHnKwde7b",
    "outputId": "b74c2ca1-ab04-4bbf-f136-8ca1eb388144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"__class__\": \"Add\",\n",
      "    \"left\": 3,\n",
      "    \"right\": {\n",
      "        \"__class__\": \"Multiply\",\n",
      "        \"left\": 5,\n",
      "        \"right\": {\n",
      "            \"__class__\": \"Exponentiate\",\n",
      "            \"left\": {\n",
      "                \"__class__\": \"Subtract\",\n",
      "                \"left\": 10,\n",
      "                \"right\": 20,\n",
      "                \"op\": \"-\"\n",
      "            },\n",
      "            \"right\": 2,\n",
      "            \"op\": \"**\"\n",
      "        },\n",
      "        \"op\": \"*\"\n",
      "    },\n",
      "    \"op\": \"+\"\n",
      "}\n",
      "Add\n",
      "Object 3\n",
      "Multiply\n",
      "Object 5\n",
      "Exponentiate {\n",
      "  \"__class__\": \"Exponentiate\",\n",
      "  \"left\": {\n",
      "    \"__class__\": \"Subtract\",\n",
      "    \"left\": 10,\n",
      "    \"right\": 20,\n",
      "    \"op\": \"-\"\n",
      "  },\n",
      "  \"right\": 2,\n",
      "  \"op\": \"**\"\n",
      "}\n",
      "Subtract\n",
      "Object 10\n",
      "Object 20\n",
      "Object 2\n",
      "-------------\n",
      "503\n"
     ]
    }
   ],
   "source": [
    "parser = tatsu.compile(grammar, asmodel=True)\n",
    "ast = parser.parse(\"3 + 5 * ( 10 - 20 ) ** 2\")\n",
    "print(json.dumps(ast.asjson(), indent=4))\n",
    "result = CalcWalker().walk(ast)\n",
    "print(\"-------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHrEBFB35RnD"
   },
   "source": [
    "**Exercise.** \n",
    "Explain the order in which the prints get executed. Which [depth-first tree traversal order](https://en.wikipedia.org/wiki/Tree_traversal) is used? How does it still manage to get to a result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "Here the order is \"recursive\", it still works because the parsing follows the parenthesis for speraration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5grOZB95sIx"
   },
   "source": [
    "So far the semantics that we have used were aiming at executing the expressions down to a value. \n",
    "\n",
    "We may, instead, want to provide a *translation semantics*, i.e. produce a translation into another language instead. \n",
    "\n",
    "For instance, this is what compilers do: they translate human-readable computer languages, into assembly-language, which then further gets translated machine language, i.e. zeros and ones that is the computer-readable and executable language. \n",
    "\n",
    "`tatsu` helps you write template-based code generators.\n",
    "\n",
    "The example below translates arithmetic expressions into posfix notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "id": "PR4Q3sTFjp3v"
   },
   "outputs": [],
   "source": [
    "from tatsu.codegen import ModelRenderer\n",
    "from tatsu.codegen import CodeGenerator\n",
    "import sys\n",
    "\n",
    "THIS_MODULE =  sys.modules[__name__]\n",
    "\n",
    "\n",
    "class PostfixCodeGenerator(CodeGenerator):\n",
    "    def __init__(self):\n",
    "        super().__init__(modules=[THIS_MODULE])\n",
    "\n",
    "\n",
    "class Number(ModelRenderer):\n",
    "    template = '''\\\n",
    "    PUSH {value}'''\n",
    "\n",
    "\n",
    "class Add(ModelRenderer):\n",
    "    template = '''\\\n",
    "    {left}\n",
    "    {right}\n",
    "    ADD'''\n",
    "\n",
    "\n",
    "class Subtract(ModelRenderer):\n",
    "    template = '''\\\n",
    "    {left}\n",
    "    {right}\n",
    "    SUB'''\n",
    "\n",
    "\n",
    "class Multiply(ModelRenderer):\n",
    "    template = '''\\\n",
    "    {left}\n",
    "    {right}\n",
    "    MUL'''\n",
    "\n",
    "\n",
    "class Divide(ModelRenderer):\n",
    "    template = '''\\\n",
    "    {left}\n",
    "    {right}\n",
    "    DIV'''\n",
    "\n",
    "class Power(ModelRenderer):\n",
    "    template = '''\\\n",
    "    {left}\n",
    "    {right}\n",
    "    DIV'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1bvUoPtgudS",
    "outputId": "db13f790-ef09-433a-b711-c78fe94d6d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"__class__\": \"Add\",\n",
      "    \"left\": 3,\n",
      "    \"right\": {\n",
      "        \"__class__\": \"Multiply\",\n",
      "        \"left\": 5,\n",
      "        \"right\": {\n",
      "            \"__class__\": \"Subtract\",\n",
      "            \"left\": 10,\n",
      "            \"right\": 20,\n",
      "            \"op\": \"-\"\n",
      "        },\n",
      "        \"op\": \"*\"\n",
      "    },\n",
      "    \"op\": \"+\"\n",
      "}\n",
      "3\n",
      "5\n",
      "10\n",
      "20\n",
      "SUB\n",
      "MUL\n",
      "ADD\n"
     ]
    }
   ],
   "source": [
    "parser = tatsu.compile(grammar, asmodel=True)\n",
    "ast = parser.parse(\"3 + 5 * ( 10 - 20 )\")\n",
    "print(json.dumps(ast.asjson(), indent=4))\n",
    "postfix = PostfixCodeGenerator().render(ast)\n",
    "print(postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsCx4jmyHt3U"
   },
   "source": [
    "## Mini-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uyc_IgeIH1Bh"
   },
   "source": [
    "\n",
    "\n",
    "1.   By incremental modifications of the last version of the above-given grammars, provide a grammar for `Mini-ML` language we saw in class.\n",
    "2.   Implement the big steps semantics of `Mini-ML` we saw in class. \n",
    "\n",
    "*Advanced.*\n",
    "\n",
    "3.   In your grammar and semantics, modify the type of constants to be booleans instead of integers or floats, and let the primitives be Not, Or, And, Nand gates, so as to eventually obtain a custom language: `Circuit-ML`. \n",
    "4.    Implement a type-checker for `Circuit-ML`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answser Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "@@grammar::Calc\n",
    "\n",
    "\n",
    "start\n",
    "    =\n",
    "    expression $\n",
    "    ;\n",
    "\n",
    "\n",
    "expression\n",
    "    =\n",
    "    | operations\n",
    "    | pair\n",
    "    | function\n",
    "    | term \n",
    "    ;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pair\n",
    "    =\n",
    "    left:expression op:',' ~ right:expression\n",
    "    ;\n",
    "    \n",
    "function\n",
    "    =\n",
    "    op:'lambda' left:term ':' ~ right:expression\n",
    "    ;\n",
    "    \n",
    "\n",
    "\n",
    "term\n",
    "    =\n",
    "    | identifier\n",
    "    | constant\n",
    "    | subexpression\n",
    "    ;\n",
    "    \n",
    "identifier\n",
    "    =\n",
    "    /[a-zA-Z]+/\n",
    "    ;\n",
    "\n",
    "subexpression\n",
    "    =\n",
    "    '(' ~ @:expression ')'\n",
    "    ;\n",
    "\n",
    "\n",
    "\n",
    "constant\n",
    "    =\n",
    "    | bool\n",
    "    | number\n",
    "    ;\n",
    "    \n",
    "bool\n",
    "    =\n",
    "    /[tf]/\n",
    "    ;\n",
    "    \n",
    "number\n",
    "    =\n",
    "    /\\d+/\n",
    "    ;\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "operations\n",
    "    =\n",
    "    | assignment\n",
    "    | add\n",
    "    | substract\n",
    "    | multiply\n",
    "    | divide\n",
    "    | exponentiate\n",
    "    | apply\n",
    "    ;\n",
    "    \n",
    "\n",
    "assignment\n",
    "    =\n",
    "    left:term op:'=' ~ right:expression\n",
    "    ;\n",
    "\n",
    "add\n",
    "    =\n",
    "    left:term op:'+' ~ right:expression\n",
    "    ;\n",
    "\n",
    "substract\n",
    "    =\n",
    "    left:term op:'-' ~ right:expression\n",
    "    ;\n",
    "\n",
    "multiply\n",
    "    =\n",
    "    left:term op:'*' ~ right:expression\n",
    "    ;\n",
    "\n",
    "divide\n",
    "    =\n",
    "    left:term '/' ~ right:expression\n",
    "    ;\n",
    "    \n",
    "exponentiate\n",
    "    =\n",
    "    left:term op:'**' ~ right:expression\n",
    "    ;\n",
    "    \n",
    "apply\n",
    "    =\n",
    "    left:term op:':' right:expression\n",
    "    ;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'op': 'lambda', 'left': 'a', 'right': {'left': {'left': 'a', 'op': '=', 'right': {'left': '2', 'op': '*', 'right': {'left': '2', 'op': '+', 'right': {'left': 'a', 'op': ':', 'right': 'b'}}}}, 'op': ',', 'right': {'left': '2', 'op': '*', 'right': '3'}}}\n",
      "{\n",
      "    \"op\": \"lambda\",\n",
      "    \"left\": \"a\",\n",
      "    \"right\": {\n",
      "        \"left\": {\n",
      "            \"left\": \"a\",\n",
      "            \"op\": \"=\",\n",
      "            \"right\": {\n",
      "                \"left\": \"2\",\n",
      "                \"op\": \"*\",\n",
      "                \"right\": {\n",
      "                    \"left\": \"2\",\n",
      "                    \"op\": \"+\",\n",
      "                    \"right\": {\n",
      "                        \"left\": \"a\",\n",
      "                        \"op\": \":\",\n",
      "                        \"right\": \"b\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"op\": \",\",\n",
      "        \"right\": {\n",
      "            \"left\": \"2\",\n",
      "            \"op\": \"*\",\n",
      "            \"right\": \"3\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parser = tatsu.compile(grammar, asmodel=True)\n",
    "ast = parser.parse(\"lambda a : ((a = 2 * 2 + a : b), (2 * 3))\")\n",
    "print(ast)\n",
    "print(json.dumps(ast.asjson(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de1Y4ULk2ZZC"
   },
   "source": [
    "## Some solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5dHu4fd2bWY",
    "outputId": "ef0fa37e-f245-40b1-ab19-7d8e389f7de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bobo:\n",
      " toto:\n",
      "   tutu\n",
      "   tata\n",
      " jojo\n"
     ]
    }
   ],
   "source": [
    "class MyTree:\n",
    "\n",
    "    def __init__(self,n=\"\",ch=None):\n",
    "        if ch is None:\n",
    "            ch = []\n",
    "        self.name = n\n",
    "        self.children = ch\n",
    "\n",
    "\n",
    "\n",
    "    def add_child(self,c):\n",
    "        if c not in self.children:\n",
    "            self.children.append(c)\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self,ind=0):\n",
    "        s = \"\"\n",
    "        for _ in range(ind):\n",
    "            s += \" \"\n",
    "        s += self.name\n",
    "        if self.children:\n",
    "            s += \":\"\n",
    "            for c in self.children:\n",
    "                s += \"\\n\"\n",
    "                for _ in range(ind):\n",
    "                    s += \" \"\n",
    "                s += c.__repr__(ind+1)\n",
    "        return s\n",
    "\n",
    "toto = MyTree(\"toto\")\n",
    "toto.add_child(MyTree(\"tutu\"))\n",
    "toto.add_child(MyTree(\"tata\"))\n",
    "bobo = MyTree(\"bobo\",[toto,MyTree(\"jojo\")])\n",
    "print(bobo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "id": "l9MmxQ3-C-0U"
   },
   "outputs": [],
   "source": [
    "ipv4pat = r\"\\d{0,3}\\.\\d{0,3}\\.\\d{0,3}\\.\\d{0,3}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "id": "FQKNwQCyDF59"
   },
   "outputs": [],
   "source": [
    "ipv6pat = r\"([0-9a-fA-F]{0,4}:){7}[0-9a-fA-F]{0,4}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "id": "6JotkZeY2tZH"
   },
   "outputs": [],
   "source": [
    "ippat = re.compile(\"(\" + ipv4pat + r\")|(\" + ipv6pat + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eSP3-tDKKhh"
   },
   "source": [
    "Post-order (LRN). The philosophy is to evaluate leafs before we can act with operations upon them. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
